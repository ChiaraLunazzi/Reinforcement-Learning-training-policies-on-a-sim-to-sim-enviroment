Eval num_timesteps=500, episode_reward=72.93 +/- 4.73
Episode length: 77.80 +/- 3.97
New best mean reward!
Eval num_timesteps=1000, episode_reward=77.35 +/- 4.15
Episode length: 81.40 +/- 3.14
New best mean reward!
Eval num_timesteps=1500, episode_reward=105.80 +/- 2.06
Episode length: 77.40 +/- 1.50
New best mean reward!
Eval num_timesteps=2000, episode_reward=108.27 +/- 1.52
Episode length: 79.20 +/- 0.98
New best mean reward!
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:01[39m < [36m0:00:00[39m , [31m1,233 it/s[39m ]
[?25h