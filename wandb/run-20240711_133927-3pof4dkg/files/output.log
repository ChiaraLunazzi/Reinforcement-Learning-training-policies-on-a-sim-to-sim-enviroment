Eval num_timesteps=500, episode_reward=75.16 +/- 6.10
Episode length: 79.40 +/- 5.12
New best mean reward!
Eval num_timesteps=1000, episode_reward=73.91 +/- 4.81
Episode length: 78.80 +/- 4.17


Eval num_timesteps=1500, episode_reward=175.49 +/- 1.20
Episode length: 128.20 +/- 0.75
New best mean reward!
Eval num_timesteps=2000, episode_reward=175.87 +/- 3.16
Episode length: 128.80 +/- 2.32
New best mean reward!
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:07[39m < [36m0:00:00[39m , [31m161 it/s[39m ]
[?25h