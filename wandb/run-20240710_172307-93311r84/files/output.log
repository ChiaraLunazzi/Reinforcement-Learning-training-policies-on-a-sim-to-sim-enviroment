Eval num_timesteps=500, episode_reward=74.81 +/- 1.07
Episode length: 79.80 +/- 1.17
New best mean reward!
Eval num_timesteps=1000, episode_reward=74.90 +/- 3.43
Episode length: 80.20 +/- 3.19
New best mean reward!
Eval num_timesteps=1500, episode_reward=77.25 +/- 4.41
Episode length: 81.60 +/- 3.50
New best mean reward!
Eval num_timesteps=2000, episode_reward=77.70 +/- 3.86
Episode length: 81.80 +/- 2.93
New best mean reward!
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:03[39m < [36m0:00:00[39m , [31m559 it/s[39m ]
[?25h