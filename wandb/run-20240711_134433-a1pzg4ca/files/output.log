Eval num_timesteps=500, episode_reward=73.56 +/- 2.76
Episode length: 78.20 +/- 2.32
New best mean reward!
Eval num_timesteps=1000, episode_reward=73.96 +/- 3.92
Episode length: 78.60 +/- 3.26
New best mean reward!
Eval num_timesteps=1500, episode_reward=74.25 +/- 4.67
Episode length: 79.20 +/- 3.82
New best mean reward!
Eval num_timesteps=2000, episode_reward=77.47 +/- 2.93
Episode length: 81.40 +/- 2.58
New best mean reward!
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:01[39m < [36m0:00:00[39m , [31m574 it/s[39m ]
[?25h