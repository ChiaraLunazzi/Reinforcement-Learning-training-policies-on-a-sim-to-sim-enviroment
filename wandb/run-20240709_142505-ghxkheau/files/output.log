Eval num_timesteps=500, episode_reward=104.68 +/- 9.04
Episode length: 100.40 +/- 6.44
New best mean reward!
Eval num_timesteps=1000, episode_reward=102.23 +/- 5.65
Episode length: 98.80 +/- 3.92
Eval num_timesteps=1500, episode_reward=102.41 +/- 4.98
Episode length: 98.60 +/- 3.61
Eval num_timesteps=2000, episode_reward=106.35 +/- 7.25
Episode length: 101.00 +/- 4.47
New best mean reward!
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m210 it/s[39m ]
[?25h