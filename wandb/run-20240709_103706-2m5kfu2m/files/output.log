Eval num_timesteps=500, episode_reward=105.46 +/- 8.44
Episode length: 101.20 +/- 5.64
New best mean reward!
Eval num_timesteps=1000, episode_reward=104.61 +/- 8.16
Episode length: 100.20 +/- 5.91
Eval num_timesteps=1500, episode_reward=103.90 +/- 10.91
Episode length: 99.20 +/- 7.33
Eval num_timesteps=2000, episode_reward=108.30 +/- 7.41
Episode length: 102.60 +/- 5.20
New best mean reward!
Eval num_timesteps=2500, episode_reward=103.15 +/- 6.50
Episode length: 99.20 +/- 4.83
Eval num_timesteps=3000, episode_reward=108.32 +/- 2.31
Episode length: 102.40 +/- 2.15
New best mean reward!
[35m 100%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m3,072/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m563 it/s[39m ]
[?25h