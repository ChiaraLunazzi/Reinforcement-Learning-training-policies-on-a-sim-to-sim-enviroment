Eval num_timesteps=500, episode_reward=103.52 +/- 6.25
Episode length: 99.60 +/- 4.67
New best mean reward!
Eval num_timesteps=1000, episode_reward=105.23 +/- 9.80
Episode length: 101.00 +/- 6.87
New best mean reward!
Eval num_timesteps=1500, episode_reward=105.27 +/- 4.87
Episode length: 101.80 +/- 2.93
New best mean reward!
Eval num_timesteps=2000, episode_reward=109.87 +/- 11.71
Episode length: 103.80 +/- 7.36
New best mean reward!
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m216 it/s[39m ]
[?25h