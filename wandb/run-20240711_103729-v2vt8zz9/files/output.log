Eval num_timesteps=500, episode_reward=73.54 +/- 2.46
Episode length: 78.20 +/- 2.56
New best mean reward!
Eval num_timesteps=1000, episode_reward=76.97 +/- 2.71
Episode length: 81.80 +/- 2.48
New best mean reward!
Eval num_timesteps=1500, episode_reward=98.41 +/- 2.02
Episode length: 70.00 +/- 1.41
New best mean reward!
Eval num_timesteps=2000, episode_reward=100.12 +/- 2.40
Episode length: 71.20 +/- 1.72
New best mean reward!
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:03[39m < [36m0:00:00[39m , [31m508 it/s[39m ]
[?25h