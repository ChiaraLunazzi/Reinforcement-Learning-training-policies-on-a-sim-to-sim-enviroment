Applying domain randomization...
Eval num_timesteps=500, episode_reward=74.32 +/- 2.78
Episode length: 78.80 +/- 2.56
New best mean reward!
Eval num_timesteps=1000, episode_reward=71.54 +/- 3.62
Episode length: 76.60 +/- 2.73
Eval num_timesteps=1500, episode_reward=72.42 +/- 6.27
Episode length: 77.40 +/- 5.68
Eval num_timesteps=2000, episode_reward=75.45 +/- 2.74
Episode length: 80.00 +/- 2.45
New best mean reward!


Eval num_timesteps=2500, episode_reward=3.60 +/- 0.09
Episode length: 7.00 +/- 0.00
Eval num_timesteps=3000, episode_reward=3.60 +/- 0.11
Episode length: 7.00 +/- 0.00
Eval num_timesteps=3500, episode_reward=3.67 +/- 0.07
Episode length: 7.00 +/- 0.00
Eval num_timesteps=4000, episode_reward=3.59 +/- 0.12
Episode length: 7.00 +/- 0.00


Eval num_timesteps=4500, episode_reward=-1.50 +/- 0.36
Episode length: 17.80 +/- 0.40
Eval num_timesteps=5000, episode_reward=-1.33 +/- 0.30
Episode length: 17.80 +/- 0.40
Eval num_timesteps=5500, episode_reward=-1.41 +/- 0.24
Episode length: 17.80 +/- 0.40
Eval num_timesteps=6000, episode_reward=-1.62 +/- 0.19
Episode length: 18.00 +/- 0.00



Eval num_timesteps=6500, episode_reward=3.79 +/- 0.02
Episode length: 7.00 +/- 0.00
Eval num_timesteps=7000, episode_reward=3.71 +/- 0.09
Episode length: 7.00 +/- 0.00
Eval num_timesteps=7500, episode_reward=3.76 +/- 0.09
Episode length: 7.00 +/- 0.00
Eval num_timesteps=8000, episode_reward=3.74 +/- 0.06
Episode length: 7.00 +/- 0.00

