Eval num_timesteps=500, episode_reward=74.49 +/- 6.33
Episode length: 78.80 +/- 5.60
New best mean reward!
Eval num_timesteps=1000, episode_reward=78.81 +/- 4.28
Episode length: 82.60 +/- 3.26
New best mean reward!
Eval num_timesteps=1500, episode_reward=39.28 +/- 3.29
Episode length: 46.60 +/- 2.24
Eval num_timesteps=2000, episode_reward=36.95 +/- 5.34
Episode length: 47.80 +/- 5.64
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:01[39m < [36m0:00:00[39m , [31m717 it/s[39m ]
[?25hMean reward: 107.40851266000001 +/- 20.81239766363541
Eval num_timesteps=500, episode_reward=74.53 +/- 3.10
Episode length: 79.60 +/- 3.01
New best mean reward!
Eval num_timesteps=1000, episode_reward=77.49 +/- 3.88
Episode length: 81.40 +/- 3.38
New best mean reward!
Eval num_timesteps=1500, episode_reward=44.27 +/- 7.29
Episode length: 55.60 +/- 14.22
Eval num_timesteps=2000, episode_reward=47.32 +/- 6.87
Episode length: 61.40 +/- 14.25
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m726 it/s[39m ]
[?25hMean reward: 249.36560611999997 +/- 1.4430638140863863
Eval num_timesteps=500, episode_reward=73.98 +/- 4.36
Episode length: 78.80 +/- 3.71
New best mean reward!
Eval num_timesteps=1000, episode_reward=74.82 +/- 3.06
Episode length: 79.80 +/- 2.40
New best mean reward!
Eval num_timesteps=1500, episode_reward=55.63 +/- 14.69
Episode length: 70.80 +/- 17.60
Eval num_timesteps=2000, episode_reward=47.86 +/- 2.12
Episode length: 62.20 +/- 0.40
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m703 it/s[39m ]

[?25hMean reward: 79.76857198 +/- 2.3585941135422974