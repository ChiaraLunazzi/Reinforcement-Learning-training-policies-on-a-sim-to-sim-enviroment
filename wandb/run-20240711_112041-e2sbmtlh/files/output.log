Applying domain randomization...
Eval num_timesteps=500, episode_reward=76.79 +/- 5.93
Episode length: 81.00 +/- 5.33
New best mean reward!
Eval num_timesteps=1000, episode_reward=78.57 +/- 1.44
Episode length: 82.60 +/- 1.02
New best mean reward!
Eval num_timesteps=1500, episode_reward=76.24 +/- 1.97
Episode length: 80.80 +/- 1.47
Eval num_timesteps=2000, episode_reward=77.62 +/- 4.02
Episode length: 81.60 +/- 3.26



Eval num_timesteps=2500, episode_reward=3.59 +/- 0.02
Episode length: 7.00 +/- 0.00
Eval num_timesteps=3000, episode_reward=3.65 +/- 0.14
Episode length: 7.00 +/- 0.00
Eval num_timesteps=3500, episode_reward=3.54 +/- 0.19
Episode length: 7.00 +/- 0.00
Eval num_timesteps=4000, episode_reward=3.57 +/- 0.15
Episode length: 7.00 +/- 0.00



Eval num_timesteps=4500, episode_reward=-1.55 +/- 0.16
Episode length: 18.00 +/- 0.00
Eval num_timesteps=5000, episode_reward=-1.39 +/- 0.53
Episode length: 17.60 +/- 0.49
Eval num_timesteps=5500, episode_reward=-1.59 +/- 0.30
Episode length: 17.80 +/- 0.40
Eval num_timesteps=6000, episode_reward=-1.41 +/- 0.28
Episode length: 17.80 +/- 0.40



Eval num_timesteps=6500, episode_reward=3.70 +/- 0.07
Episode length: 7.00 +/- 0.00
Eval num_timesteps=7000, episode_reward=3.63 +/- 0.10
Episode length: 7.00 +/- 0.00
Eval num_timesteps=7500, episode_reward=3.69 +/- 0.13
Episode length: 7.00 +/- 0.00
Eval num_timesteps=8000, episode_reward=3.74 +/- 0.13
Episode length: 7.00 +/- 0.00



Eval num_timesteps=8500, episode_reward=3.67 +/- 0.10
Episode length: 7.00 +/- 0.00
Eval num_timesteps=9000, episode_reward=3.59 +/- 0.07
Episode length: 7.00 +/- 0.00
Eval num_timesteps=9500, episode_reward=3.64 +/- 0.12
Episode length: 7.00 +/- 0.00
Eval num_timesteps=10000, episode_reward=3.66 +/- 0.11
Episode length: 7.00 +/- 0.00



Eval num_timesteps=10500, episode_reward=3.62 +/- 0.07
Episode length: 7.00 +/- 0.00
Eval num_timesteps=11000, episode_reward=3.73 +/- 0.08
Episode length: 7.00 +/- 0.00
Eval num_timesteps=11500, episode_reward=3.63 +/- 0.08
Episode length: 7.00 +/- 0.00
Eval num_timesteps=12000, episode_reward=3.72 +/- 0.06
Episode length: 7.00 +/- 0.00


Eval num_timesteps=12500, episode_reward=3.54 +/- 0.07
Episode length: 7.00 +/- 0.00
Eval num_timesteps=13000, episode_reward=3.63 +/- 0.04
Episode length: 7.00 +/- 0.00
[35m  13%[39m [38m‚îÅ‚îÅ‚îÅ‚ï∫‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[39m [32m13,000/100,000 [39m [ [33m0:00:54[39m < [36m0:05:38[39m , [31m258 it/s[39m ]
[?25hMean reward: 3.5842328400000003 +/- 0.14816249913096904