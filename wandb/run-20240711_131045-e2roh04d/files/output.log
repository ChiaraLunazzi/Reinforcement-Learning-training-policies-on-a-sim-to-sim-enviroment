Eval num_timesteps=500, episode_reward=77.38 +/- 3.12
Episode length: 81.20 +/- 2.48
New best mean reward!
Eval num_timesteps=1000, episode_reward=75.62 +/- 4.71
Episode length: 79.80 +/- 4.07
Eval num_timesteps=1500, episode_reward=39.72 +/- 6.12
Episode length: 47.60 +/- 6.05
Eval num_timesteps=2000, episode_reward=40.30 +/- 3.17
Episode length: 50.00 +/- 5.90
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:01[39m < [36m0:00:00[39m , [31m742 it/s[39m ]
[?25hMean reward: 105.14423822 +/- 17.733888809537042
Eval num_timesteps=500, episode_reward=74.41 +/- 6.08
Episode length: 79.40 +/- 5.39
New best mean reward!
Eval num_timesteps=1000, episode_reward=74.29 +/- 2.22
Episode length: 79.20 +/- 1.94
Eval num_timesteps=1500, episode_reward=44.18 +/- 7.42
Episode length: 55.20 +/- 14.58
Eval num_timesteps=2000, episode_reward=40.77 +/- 5.98
Episode length: 49.40 +/- 11.84
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m748 it/s[39m ]
[?25hMean reward: 249.66520142000002 +/- 1.4321605093207401
Eval num_timesteps=500, episode_reward=73.73 +/- 3.06
Episode length: 78.20 +/- 2.93
New best mean reward!
Eval num_timesteps=1000, episode_reward=73.69 +/- 4.51
Episode length: 78.60 +/- 4.32
Eval num_timesteps=1500, episode_reward=55.38 +/- 6.81
Episode length: 69.20 +/- 7.63
Eval num_timesteps=2000, episode_reward=56.14 +/- 12.31
Episode length: 70.80 +/- 16.12
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:01[39m < [36m0:00:00[39m , [31m708 it/s[39m ]

[?25hMean reward: 79.81183097999998 +/- 1.645335501867914