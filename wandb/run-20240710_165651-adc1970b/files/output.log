Eval num_timesteps=500, episode_reward=73.38 +/- 6.23
Episode length: 78.00 +/- 5.48
New best mean reward!
Eval num_timesteps=1000, episode_reward=74.72 +/- 2.23
Episode length: 79.80 +/- 1.83
New best mean reward!
Eval num_timesteps=1500, episode_reward=0.26 +/- 0.09
Episode length: 9.00 +/- 0.00
[35m  90%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•ºâ”â”[39m [32m1,798/2,000 [39m [ [33m0:00:01[39m < [36m0:00:01[39m , [31m1,077 it/s[39m ]
/home/chiar/anaconda3/envs/mldl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py:146: UserWarning: You have specified a mini-batch size of 160, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1024`, after every 6 untruncated mini-batches, there will be a truncated mini-batch of size 64
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=1024 and n_envs=1)
Eval num_timesteps=2000, episode_reward=0.29 +/- 0.13
Episode length: 9.00 +/- 0.00
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m982 it/s[39m ]
[?25h