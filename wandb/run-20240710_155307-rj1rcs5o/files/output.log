Eval num_timesteps=500, episode_reward=152.70 +/- 24.18
Episode length: 160.60 +/- 14.75
New best mean reward!
Eval num_timesteps=1000, episode_reward=155.54 +/- 19.95
Episode length: 171.00 +/- 19.77
New best mean reward!
Eval num_timesteps=1500, episode_reward=159.31 +/- 12.30
Episode length: 169.80 +/- 11.77
New best mean reward!
[35m  90%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━╺━━[39m [32m1,799/2,000 [39m [ [33m0:00:01[39m < [36m0:00:01[39m , [31m980 it/s[39m ]
/home/chiar/anaconda3/envs/mldl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py:146: UserWarning: You have specified a mini-batch size of 224, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2048`, after every 9 untruncated mini-batches, there will be a truncated mini-batch of size 32
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=1)
Eval num_timesteps=2000, episode_reward=179.39 +/- 33.88
Episode length: 179.00 +/- 20.87
New best mean reward!
[35m 100%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m2,048/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m803 it/s[39m ]
[?25h