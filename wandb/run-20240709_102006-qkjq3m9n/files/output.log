Eval num_timesteps=500, episode_reward=104.89 +/- 10.15
Episode length: 100.40 +/- 7.39
New best mean reward!
Eval num_timesteps=1000, episode_reward=107.67 +/- 8.34
Episode length: 101.60 +/- 5.46
New best mean reward!
Eval num_timesteps=1500, episode_reward=105.84 +/- 3.40
Episode length: 102.20 +/- 2.14
Eval num_timesteps=2000, episode_reward=106.84 +/- 6.67
Episode length: 100.80 +/- 5.11
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:03[39m < [36m0:00:00[39m , [31m525 it/s[39m ]
[?25h