Eval num_timesteps=500, episode_reward=105.00 +/- 7.45
Episode length: 100.60 +/- 5.57
New best mean reward!
Eval num_timesteps=1000, episode_reward=105.67 +/- 5.43
Episode length: 101.20 +/- 4.35
New best mean reward!
Eval num_timesteps=1500, episode_reward=102.52 +/- 8.94
Episode length: 98.80 +/- 6.40
Eval num_timesteps=2000, episode_reward=100.68 +/- 7.36
Episode length: 97.20 +/- 5.53
Eval num_timesteps=2500, episode_reward=108.85 +/- 2.93
Episode length: 103.00 +/- 1.41
New best mean reward!
Eval num_timesteps=3000, episode_reward=101.82 +/- 7.42
Episode length: 98.80 +/- 5.71
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m3,072/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m219 it/s[39m ]
[?25h