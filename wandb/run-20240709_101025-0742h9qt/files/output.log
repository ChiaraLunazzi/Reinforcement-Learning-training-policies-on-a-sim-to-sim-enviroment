Eval num_timesteps=500, episode_reward=99.16 +/- 6.14
Episode length: 96.20 +/- 5.11
New best mean reward!
Eval num_timesteps=1000, episode_reward=105.10 +/- 4.78
Episode length: 100.20 +/- 3.43
New best mean reward!
Eval num_timesteps=1500, episode_reward=4.03 +/- 0.07
Episode length: 7.00 +/- 0.00
Eval num_timesteps=2000, episode_reward=3.82 +/- 0.11
Episode length: 7.00 +/- 0.00
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:03[39m < [36m0:00:00[39m , [31m614 it/s[39m ]
[?25h