Eval num_timesteps=500, episode_reward=95.88 +/- 6.47
Episode length: 93.80 +/- 5.15
New best mean reward!
Eval num_timesteps=1000, episode_reward=106.69 +/- 6.60
Episode length: 101.20 +/- 4.92
New best mean reward!
Eval num_timesteps=1500, episode_reward=100.15 +/- 8.68
Episode length: 96.80 +/- 6.24
Eval num_timesteps=2000, episode_reward=106.88 +/- 9.33
Episode length: 101.60 +/- 6.25
New best mean reward!
Eval num_timesteps=2500, episode_reward=106.06 +/- 5.66
Episode length: 101.60 +/- 3.44
Eval num_timesteps=3000, episode_reward=107.23 +/- 5.63
Episode length: 101.40 +/- 3.32
New best mean reward!
[35m 100%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m3,072/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m402 it/s[39m ]
[?25h