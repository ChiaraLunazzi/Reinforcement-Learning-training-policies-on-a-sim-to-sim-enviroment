Eval num_timesteps=500, episode_reward=108.79 +/- 5.03
Episode length: 102.80 +/- 3.71
New best mean reward!
Eval num_timesteps=1000, episode_reward=110.07 +/- 4.15
Episode length: 104.00 +/- 2.61
New best mean reward!
Eval num_timesteps=1500, episode_reward=103.23 +/- 8.04
Episode length: 98.80 +/- 6.21
Eval num_timesteps=2000, episode_reward=110.12 +/- 3.12
Episode length: 103.40 +/- 2.06
New best mean reward!
Eval num_timesteps=2500, episode_reward=105.95 +/- 7.19
Episode length: 101.40 +/- 5.16
Eval num_timesteps=3000, episode_reward=103.93 +/- 6.80
Episode length: 100.40 +/- 4.59
[35m 100%[39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [32m3,072/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m555 it/s[39m ]
[?25h