Eval num_timesteps=500, episode_reward=105.37 +/- 10.32
Episode length: 100.60 +/- 7.42
New best mean reward!
Eval num_timesteps=1000, episode_reward=107.53 +/- 2.80
Episode length: 103.00 +/- 1.90
New best mean reward!
Eval num_timesteps=1500, episode_reward=107.12 +/- 1.08
Episode length: 102.80 +/- 0.75
Eval num_timesteps=2000, episode_reward=108.36 +/- 4.68
Episode length: 102.60 +/- 3.26
New best mean reward!
Eval num_timesteps=2500, episode_reward=107.69 +/- 6.47
Episode length: 102.00 +/- 4.20
Eval num_timesteps=3000, episode_reward=108.90 +/- 7.51
Episode length: 102.40 +/- 5.31
New best mean reward!
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m3,072/2,000 [39m [ [33m0:00:01[39m < [36m0:00:00[39m , [31m299 it/s[39m ]
[?25h