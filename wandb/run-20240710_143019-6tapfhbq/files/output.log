Eval num_timesteps=500, episode_reward=236.21 +/- 96.54
Episode length: 198.20 +/- 47.91
New best mean reward!
Eval num_timesteps=1000, episode_reward=212.80 +/- 83.22
Episode length: 184.40 +/- 35.13
[35m  74%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸â”â”â”â”â”â”â”[39m [32m1,481/2,000 [39m [ [33m0:00:01[39m < [36m0:00:01[39m , [31m836 it/s[39m ]
/home/chiar/anaconda3/envs/mldl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py:146: UserWarning: You have specified a mini-batch size of 224, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2048`, after every 9 untruncated mini-batches, there will be a truncated mini-batch of size 32
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=1)
Eval num_timesteps=1500, episode_reward=256.76 +/- 72.74
Episode length: 206.40 +/- 33.26
New best mean reward!
Eval num_timesteps=2000, episode_reward=235.49 +/- 80.53
Episode length: 206.60 +/- 44.92
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m613 it/s[39m ]
[?25h