Eval num_timesteps=500, episode_reward=106.02 +/- 7.75
Episode length: 100.80 +/- 4.87
New best mean reward!
Eval num_timesteps=1000, episode_reward=105.42 +/- 8.53
Episode length: 100.20 +/- 5.81
Eval num_timesteps=1500, episode_reward=104.64 +/- 6.74
Episode length: 100.20 +/- 5.04
Eval num_timesteps=2000, episode_reward=109.58 +/- 4.40
Episode length: 103.40 +/- 2.24
New best mean reward!


[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:08[39m < [36m0:00:00[39m , [31m212 it/s[39m ]
[?25h