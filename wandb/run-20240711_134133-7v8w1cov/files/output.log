Eval num_timesteps=500, episode_reward=76.36 +/- 4.81
Episode length: 80.60 +/- 3.93
New best mean reward!
Eval num_timesteps=1000, episode_reward=76.45 +/- 2.52
Episode length: 80.40 +/- 2.42
New best mean reward!
Eval num_timesteps=1500, episode_reward=59.55 +/- 1.31
Episode length: 64.40 +/- 1.36
Eval num_timesteps=2000, episode_reward=59.51 +/- 1.46
Episode length: 64.60 +/- 1.36
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:02[39m < [36m0:00:00[39m , [31m646 it/s[39m ]
[?25h
Traceback (most recent call last):
  File "udr_ole.py", line 63, in <module>
    main()
  File "udr_ole.py", line 58, in main
    train_test(args, train_env, test_env, w)
  File "udr_ole.py", line 39, in train_test
    mean_reward, std_reward = evaluate_policy(model, test_env, n_eval_episodes=args.test_episodes)
NameError: name 'evaluate_policy' is not defined