Eval num_timesteps=500, episode_reward=76.36 +/- 4.81
Episode length: 80.60 +/- 3.93
New best mean reward!
Eval num_timesteps=1000, episode_reward=76.45 +/- 2.52
Episode length: 80.40 +/- 2.42
New best mean reward!
Eval num_timesteps=1500, episode_reward=34.63 +/- 4.53
Episode length: 42.60 +/- 3.38
Eval num_timesteps=2000, episode_reward=40.11 +/- 4.20
Episode length: 46.60 +/- 2.80
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:01[39m < [36m0:00:00[39m , [31m754 it/s[39m ]
[?25hMean reward: 107.98325292 +/- 17.01896749139012
Eval num_timesteps=500, episode_reward=73.44 +/- 4.75
Episode length: 78.00 +/- 4.34
New best mean reward!
Eval num_timesteps=1000, episode_reward=72.77 +/- 4.53
Episode length: 77.80 +/- 4.26
Eval num_timesteps=1500, episode_reward=47.02 +/- 6.97
Episode length: 61.00 +/- 14.31
Eval num_timesteps=2000, episode_reward=44.01 +/- 6.92
Episode length: 55.20 +/- 14.13
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:01[39m < [36m0:00:00[39m , [31m744 it/s[39m ]
[?25hMean reward: 249.40671385999997 +/- 1.2801250236856387
Eval num_timesteps=500, episode_reward=73.10 +/- 6.10
Episode length: 77.40 +/- 5.31
New best mean reward!
Eval num_timesteps=1000, episode_reward=73.90 +/- 7.24
Episode length: 78.40 +/- 6.15
New best mean reward!
Eval num_timesteps=1500, episode_reward=57.67 +/- 6.70
Episode length: 70.20 +/- 6.31
Eval num_timesteps=2000, episode_reward=55.14 +/- 7.31
Episode length: 68.00 +/- 6.96
[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m2,048/2,000 [39m [ [33m0:00:01[39m < [36m0:00:00[39m , [31m724 it/s[39m ]

[?25hMean reward: 79.77376566 +/- 1.9872891723466468